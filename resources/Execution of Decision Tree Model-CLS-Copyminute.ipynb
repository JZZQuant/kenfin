{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Instructions\n",
    "<i>You can run the notebook document sequentially (one cell at a time) by pressing <b> shift + enter</b>. While a cell is running, a [*] will display on the left. When it has been run, a number will display indicating the order in which it was run in the notebook [8].</i>\n",
    "\n",
    "<i>Enter edit mode by pressing <b>`Enter`</b> or using the mouse to click on a cell's editor area. Edit mode is indicated by a green cell border and a prompt showing in the editor area.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "Hyperparameters cannot be learned by the model but need to be specified by the user before training the models. In this notebook, we will find the best hyperparameters for random forest model created in the previous section using random search and grid search cross validation techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with below steps which you already know!\n",
    "1. Import the data\n",
    "2. Define predictor variables and a target variable\n",
    "3. Split the data into train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV ,GridSearchCV \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "import talib as ta\n",
    "\n",
    "data_total = pd.read_csv('ICICIBANK19JANFUT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_total=data_total[1000:]\n",
    "data_total.close.plot(figsize=(15,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atr=ta.ATR(data_total.high,data_total.low,data_total.close,timeperiod=30)\n",
    "#ret=data_total.close.pct_change().shift(-1)\n",
    "#atr[ret.abs()>0.005]=0\n",
    "atr.plot(figsize=(15,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.get_function_groups().keys()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ta.get_function_groups()['Momentum Indicators']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "?ta.ATR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create the features and train-test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(data):\n",
    "    \n",
    "    # Returns\n",
    "    data=data.copy()\n",
    "    col1=set(data.columns)\n",
    "    data['ret1'] = data.close.pct_change()\n",
    "    data['ret2'] = data.close.pct_change(2)\n",
    "    data['ret5'] = data.close.pct_change(5)\n",
    "    data['ret20'] = data.close.pct_change(20)\n",
    "    data['ret30'] = data.close.pct_change(30)\n",
    "\n",
    "    data['retl1'] = data.low.pct_change()\n",
    "    data['retl2'] = data.low.pct_change(2)\n",
    "    data['retl5'] = data.low.pct_change(5)\n",
    "    data['reth1'] = data.high.pct_change()\n",
    "    data['reth2'] = data.high.pct_change(2)\n",
    "    data['reth5'] = data.high.pct_change(5)\n",
    "    \n",
    "    \n",
    "    data['retr5'] = data.ret1.rolling(5).sum()\n",
    "    data['retr10'] = data.ret1.rolling(10).sum()\n",
    "    data['retr20'] = data.ret1.rolling(20).sum()\n",
    "    data['retr40'] = data.ret1.rolling(40).sum()\n",
    "\n",
    "    # Standard Deviation\n",
    "    data['std5'] = data.ret1.rolling(5).std()\n",
    "    data['std10'] = data.ret1.rolling(10).std()\n",
    "    data['std20'] = data.ret1.rolling(20).std()\n",
    "    data['std40'] = data.ret1.rolling(40).std()\n",
    "\n",
    "\n",
    "    data['vel1'] = (2*data.close-data.high-data.low)\n",
    "    data['vel5'] = data.vel1.rolling(5).sum()\n",
    "    data['vel10'] = data.vel1.rolling(10).sum()\n",
    "    data['vel20'] = data.vel1.rolling(20).sum()\n",
    "    data['vel40'] = data.vel1.rolling(40).sum()\n",
    "    \n",
    "    data['stdv5'] = data.vel1.rolling(5).std()\n",
    "    data['stdv10'] = data.vel1.rolling(10).std()\n",
    "    data['stdv20'] = data.vel1.rolling(20).std()\n",
    "    data['stdv40'] = data.vel1.rolling(40).std()\n",
    "    \n",
    "    \n",
    "    data['stdv5'] = data.volume.rolling(5).std()\n",
    "    data['stdvv10'] = data.volume.rolling(10).std()\n",
    "    data['stdvv20'] = data.volume.rolling(20).std()\n",
    "    data['stdvv40'] = data.volume.rolling(40).std()\n",
    "    \n",
    "        \n",
    "    # ADDED volume profile and acc, this reduced low vol peformance but increased the high vol performance\n",
    " \n",
    "    data['vol1'] = data.volume.diff()\n",
    "    data['vol5'] = data.volume.diff(5)\n",
    "    data['vol10'] = data.volume.diff(10)\n",
    "    data['vol20'] = data.volume.diff(20)\n",
    "    data['vol40'] = data.volume.diff(40)\n",
    "    \n",
    "    data['vols5'] = data.volume.rolling(5).sum()\n",
    "    data['vols10'] = data.volume.rolling(10).sum()\n",
    "    data['vols20'] = data.volume.rolling(20).sum()\n",
    "    data['vols40'] = data.volume.rolling(40).sum()\n",
    "    \n",
    "    data['acc1'] = data.vel1.diff()\n",
    "    data['acc5'] = data.vel1.diff(5)\n",
    "    data['acc10'] = data.vel1.diff(10)\n",
    "    data['acc20'] = data.vel1.diff(20)\n",
    "    data['acc40'] = data.vel1.diff(40)\n",
    "     \n",
    "    # Candlestick Patterns\n",
    "    data['HAMMER']=ta.CDLHAMMER(data.open, data.high, data.low, data.close)\n",
    "    data['DOJI']=ta.CDLDOJI(data.open, data.high, data.low, data.close)\n",
    "    data['SHOOTINGSTAR']=ta.CDLSHOOTINGSTAR(data.open, data.high, data.low, data.close)\n",
    "    \n",
    "    # Technical Indicators\n",
    "    \n",
    "# changed the timeperiod from 14 to 30\n",
    "    data['AROONOSC']=ta.AROONOSC( data.high, data.low ,timeperiod=30)\n",
    "    data['RSI']=ta.RSI(data.close,timeperiod=30)\n",
    "    data['ADXR']=ta.ADXR(  data.high, data.low, data.close,timeperiod=30)    \n",
    "    data['ATR']=ta.ATR(data.high,data.low,data.close,timeperiod=30)\n",
    "    data['ATR']=ta.ATR(data.high,data.low,data.close,timeperiod=5)\n",
    "\n",
    "    # Future returns\n",
    "#    data['retFut1'] = data.ret1.shift(-1)\n",
    "# changed k from 30 to 60\n",
    "    k=30\n",
    "    data['retFut1'] = np.where(((data.close>data.close.rolling(k).mean())\n",
    "                               &(data.close>data.shift(-k).close.rolling(k).mean())),-1,\n",
    "                               np.where(((data.close<data.close.rolling(k).mean())\n",
    "                                        &(data.close<data.shift(-k).close.rolling(k).mean())),1,0))\n",
    "\n",
    "    \n",
    "    col2=set(data.columns)\n",
    "\n",
    "    # Define predictor variables (X) and a target variable (y)\n",
    "    data = data.dropna()\n",
    "    predictor_list = list(col2-col1)\n",
    "    predictor_list.remove('retFut1')\n",
    "    X = data[predictor_list]\n",
    "#    y = np.where((data.close>data.close.rolling(30).mean())&(data.close>data.shift(-30).close.rolling(30).mean()),1,\n",
    "#                 np.where((data.close<data.close.rolling(30).mean())&(data.close<data.shift(-30).close.rolling(30).mean()),-1,0))\n",
    "    y = data.retFut1\n",
    "#    y = np.where(data.retFut1>0,1,-1)\n",
    "    y = pd.Series(y)\n",
    "    return X , y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=create_features(data_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "knn= KMeans(2)\n",
    "X['Cluster']=knn.fit_predict(X)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X.Cluster[X.Cluster!=X.Cluster.shift(1)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(np.nancumprod(X.iloc[-len_exec:].ret1+1))\n",
    "plt.scatter(X.iloc[-len_exec:][X.iloc[-len_exec:].Cluster==0].index,np.nancumprod(X.iloc[-len_exec:].ret1+1)[X.iloc[-len_exec:].Cluster==0])\n",
    "plt.scatter(X.iloc[-len_exec:][X.iloc[-len_exec:].Cluster==1].index,np.nancumprod(X.iloc[-len_exec:].ret1+1)[X.iloc[-len_exec:].Cluster==1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_len=len(data_total)-len(X)\n",
    "len_exec=375*1\n",
    "perf=0\n",
    "min_len, len_exec, perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exe=data_total[-(min_len+perf+len_exec):].copy()\n",
    "data=data_total[:-(min_len+perf+len_exec)].copy()\n",
    "\n",
    "X,y=create_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exe.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key hyperparameters in random forest method are\n",
    "- n_estimators,\n",
    "- max_features, \n",
    "- max_depth, \n",
    "- min_samples_leaf, \n",
    "- and bootstrap.   \n",
    "\n",
    "We have defined below a range of values for each of these hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a hyperparameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dt_hp_grid():\n",
    "\n",
    "\n",
    "    # Number of features to consider at every split\n",
    "    max_features = [round(x,2) for x in np.linspace(start = 0.1, stop = 1.0, num = 100)]\n",
    "\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [int(x) for x in np.linspace(start = 1, stop = 51, num = 50)]\n",
    "\n",
    "\n",
    "    # Save these parameters in a dictionry\n",
    "    param_grid = {\n",
    "                   'max_features': max_features,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                  }\n",
    "    return param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search\n",
    "The RandomizedSearchCV function from sklearn.model_selection package is used to find best hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid=create_dt_hp_grid()\n",
    "# Create the base model to tune\n",
    "def perform_RSCV(param_grid,X_train, y_train):\n",
    "    random_forest = RandomForestClassifier(n_estimators = 100,random_state= 42,bootstrap=True)#,class_weight=\"balanced_subsample\")\n",
    "    rf_random = RandomizedSearchCV(estimator = random_forest, \n",
    "                                   param_distributions = param_grid, \n",
    "                                   n_iter = 60,                               \n",
    "                                   random_state= 42,\n",
    "                                   iid=False,\n",
    "                                   cv =10,\n",
    "                                   verbose=1\n",
    "                                   )\n",
    "    rf_random.fit(X_train, y_train)\n",
    "    return rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RandomizedSearchCV takes following parameter as input\n",
    "\n",
    "1. estimator: The base estimator model for which best hyperparameter values are found.\n",
    "2. param_distributions: Dictionary of parameter names and list of values to try.\n",
    "3. n_iter: Number of parameters that are tried to find the best values.\n",
    "4. random_state: The random seed value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best hyperparameters values for the random forest model is found below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params=perform_RSCV(param_grid,X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform GridSearch in the vicinity of the best parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_GSCV(best_params,X_train, y_train):\n",
    "    random_forest = RandomForestClassifier(n_estimators = 100,random_state= 42,bootstrap= True)#,class_weight=\"balanced_subsample\")\n",
    "    \n",
    "    \n",
    "    if best_params['max_features'] >0.95:\n",
    "        max_f=[float(i) for i in np.linspace(best_params['max_features']-0.05,1,4)]\n",
    "    elif best_params['max_features'] <0.05:\n",
    "        max_f=[float(i) for i in np.linspace(0.01,best_params['max_features']+0.05,4)]\n",
    "    else:\n",
    "        max_f=[float(i) for i in np.linspace(best_params['max_features']-0.05,best_params['max_features']+0.05,4)]\n",
    "        \n",
    "    if best_params['min_samples_leaf'] <2:\n",
    "        min_s=[int(i) for i in np.linspace(1,best_params['min_samples_leaf']+ 4,4)]\n",
    "    else:\n",
    "        min_s=[int(i) for i in np.linspace(best_params['min_samples_leaf']- 2,best_params['min_samples_leaf']+ 2,4)]        \n",
    "         \n",
    "\n",
    "    \n",
    "    param_grid = {\n",
    "               'max_features': max_f ,\n",
    "               'min_samples_leaf': min_s\n",
    "              }\n",
    "    \n",
    "    \n",
    "    rf_grid = GridSearchCV(estimator = random_forest, \n",
    "                               param_grid = param_grid,  \n",
    "                               iid=False,\n",
    "                               cv=10\n",
    "                               )\n",
    "    rf_grid.fit(X_train, y_train)\n",
    "\n",
    "    return rf_grid\n",
    "\n",
    "model=perform_GSCV(best_params,X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=perform_GSCV(best_params,X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we train the model created using the best hyperparameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search\n",
    "\n",
    "Similarly, we can find the best model using grid search cross validation technique. Since this method is time consuming as it tries out all possible combinations, we have defined below less hyperparameters values for illustration purpose only. You may specify more values for hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code finds the best hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pickle_path = 'model_pickle_Minute_Best_reverse_signal.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,model_pickle_path):\n",
    "    model_pickle = open(model_pickle_path, 'wb')\n",
    "    pickle.dump(model, model_pickle)\n",
    "    model_pickle.close()\n",
    "    \n",
    "save_model(model,model_pickle_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_train(data,model_pickle_path):\n",
    "    X,y=create_features(data)\n",
    "    param_grid=create_dt_hp_grid()\n",
    "    best_params=perform_RSCV(param_grid,X, y)\n",
    "    model=perform_GSCV(best_params,X, y)\n",
    "    save_model(model,model_pickle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=create_features(data_exe)\n",
    "with open(model_pickle_path, 'rb') as model_unpickle:\n",
    "    model1 = pickle.load(model_unpickle)\n",
    "cls1=model1.best_estimator_\n",
    "predictions= cls1.predict(X)\n",
    "#cluster=knn.fit_predict(X)\n",
    "#predictions=pd.Series(predictions*cluster)\n",
    "predictions=pd.Series(predictions)\n",
    "predictions=predictions.replace(0,method='ffill')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "ret=data_exe.close.pct_change().shift(-1).iloc[-len_exec:]\n",
    "ret[ret.abs()>0.005]=0\n",
    "strategy_perf1=pd.Series(predictions[-len_exec:]*ret.values)\n",
    "plt.plot(np.nancumprod(strategy_perf1+1))\n",
    "plt.plot(np.nancumprod(ret+1))\n",
    "plt.legend(['Strat'])\n",
    "\n",
    "#plt.plot(np.nancumprod(data_exe.close.pct_change().shift(-1).iloc[-len_exec:]+1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "list(cluster==0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X['Cluster']=knn.fit_predict(X)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.plot(X.Cluster,marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(X.iloc[-len_exec:].Cluster==0).shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "strategy_perf1.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.nancumprod(X[X.Cluster==0].iloc[-len_exec:].ret1+1)[-1],np.nancumprod(X[X.Cluster==1].iloc[-len_exec:].ret1+1)[-1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn import tree\n",
    "import graphviz\n",
    "dot_data = tree.export_graphviz(model.best_estimator_, \n",
    "                                out_file=None, \n",
    "                                filled=True,   \n",
    "                                feature_names=list(X.columns))  \n",
    "graphviz.Source(dot_data) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictions[predictions!=0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictions=pd.Series(predictions)\n",
    "len(predictions[predictions!=predictions.shift(1)])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ret=data_exe.close.pct_change().shift(-1).iloc[-len_exec:]\n",
    "ret[ret.abs()>0.005]=.0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.hist(ret.dropna(),bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data_exe.close.pct_change().std()*4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the model on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will retrain the model whenever the past 20 days (1 month)  performance is negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_perf=[]\n",
    "for i in range(len(data_total)):\n",
    "    if i>373: \n",
    "        X,y=create_features(data_total.iloc[:i])\n",
    "        model_unpickle = open(model_pickle_path, 'rb')\n",
    "        model = pickle.load(model_unpickle)\n",
    "        cls=model.best_estimator_\n",
    "        predictions= cls.predict(X)\n",
    "        strategy_perf.append(predictions[-1])\n",
    "        \n",
    "        if i//374==0:\n",
    "            re_train(data_total.iloc[:i],model_pickle_path)\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        model_unpickle = open(model_pickle_path, 'rb')\n",
    "        model = pickle.load(model_unpickle)\n",
    "        cls=model.best_estimator_\n",
    "        predictions= cls.predict(X)\n",
    "        strategy_perf.append(predictions[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_total.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(strategy_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_perf =pd.Series(strategy_perf).replace(0,method='ffill')\n",
    "strategy_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the strategy performance on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_exe)-375-min_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "strategy_perf1=pd.Series(strategy_perf*data_total.close.pct_change().shift(-1).iloc[-len(strategy_perf):].values)\n",
    "plt.plot(np.nancumprod(strategy_perf1+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Practice\n",
    "\n",
    "You can try it yourself of how the random forest model created through RandomSearchCV and GridSearchCV performs on test dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
